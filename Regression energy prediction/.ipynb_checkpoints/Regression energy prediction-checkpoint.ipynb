{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e20bc5b37f5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mload_electricity_school_data\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_electricity_education\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfeature_encoding_and_data_splitting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprepare_data_simple_encoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprepare_data_polynomial_encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlinear_regression_functions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlearn_parameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_loss_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_test_and_prediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_linear_regression_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\Academic\\AML\\Project\\Regression energy prediction\\linear_regression_functions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;31m# from tensorflow.python import keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;31m# from tensorflow.python.layers import layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_lib.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# pylint: disable=unused-import,line-too-long,wildcard-import,g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column_v2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence_feature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparse_tensor\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msparse_tensor_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_tf_layers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mInputSpec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInputSpec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\models.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\activations.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0madvanced_activations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mserialize_keras_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistributed_training_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mautocast_variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mloss_scale_optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayer_serialization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\mixed_precision\\loss_scale_optimizer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmirrored_strategy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mone_device_strategy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtpu_strategy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os.path import join\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib.pyplot import figure\n",
    "import datetime\n",
    "\n",
    "from load_and_process_data import process_data\n",
    "from load_electricity_school_data import load_electricity_education\n",
    "from feature_encoding_and_data_splitting import split_data, prepare_data_simple_encoding, prepare_data_polynomial_encoding\n",
    "from linear_regression_functions import learn_parameters, plot_loss_history, plot_test_and_prediction, plot_linear_regression_weights\n",
    "\n",
    "\n",
    "\n",
    "#import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the process_data function to load and handle missing data: The missing data is shown below\n",
    "Building features:\n",
    "53.4% of the year built\n",
    "75.5% of the floor count\n",
    "\n",
    "Weather features:\n",
    "9.5% of the cloud coverage\n",
    "0.1% of the dew temperature\n",
    "36.0% of the precipitation depth\n",
    "7.6% of the sea level pressure\n",
    "4.5% of the wind speed\n",
    "0.2% of the wind direction.\n",
    "\n",
    "For weather: I filled missing data using average of the closest non missing values of that feature.\n",
    "For building: I filled the missing data with the mean of the feature for that building's primary use group.\n",
    "\n",
    "Using load_electricity_education function, I load only data from educational buildings. \n",
    "\n",
    "The process_data function also combines the building data with the weather data and both are used together to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafolder = '../ashrae-energy-prediction/'\n",
    "pd_all = process_data(datafolder)\n",
    "# Load all Education buildings Electricity consumption data that has good \n",
    "# electricity meter reading values:\n",
    "pd_educational = load_electricity_education(pd_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_educational.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"meter_reading\"]).plot(figsize =(15,7), ylabel = \"mean hourly electricity readings (kWh)\", title = \"mean hourly electricity readings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows the electricity meter data averaged for all educational buildings over 1 year "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the first 11 months of data as training data and last month (decemeber) to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_dec(pd_dataframe):\n",
    "    # split it ~90% on train + validation (11 months) and ~10% on test (1 month)\n",
    "    pd_educational = pd_dataframe.copy()\n",
    "    pd_train = pd_educational.loc[pd.to_datetime(pd_educational[\"timestamp\"]) < datetime.datetime(2016, 12, 1)] \n",
    "    pd_test = pd_educational.loc[pd.to_datetime(pd_educational[\"timestamp\"]) > datetime.datetime(2016, 11, 30)]  \n",
    "    timestamp_train = pd_train.pop('timestamp')  \n",
    "    timestamp_test = pd_test.pop('timestamp') \n",
    "    \n",
    "    return pd_train, pd_test, timestamp_train, timestamp_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below does the simple encoding. For simple encoding, I replaced the timestamp feature with hour, weekday, and month features. I also normalized all the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_simple_encoding_dec(pd_dataframe):\n",
    "  # Timestamp feature encoding:\n",
    "    ## Looking at the data during data exploration, data shows clear dependence on\n",
    "    ## time of the day and weekend/weekday. There is also some month variation\n",
    "    ## of the meter_reading data. I will thus split the timestamp data into month,\n",
    "    ## weekday and hour that I will then encode using regular numeric encoding (normalize)\n",
    "    pd_educational = pd_dataframe.copy()\n",
    "    pd_educational['month'] = pd.to_datetime(pd_educational[\"timestamp\"]).dt.month\n",
    "    pd_educational['weekday'] = pd.to_datetime(pd_educational[\"timestamp\"]).dt.weekday\n",
    "    pd_educational['hour'] = pd.to_datetime(pd_educational[\"timestamp\"]).dt.hour\n",
    "    pd_train, pd_test, timestamp_train, timestamp_test = split_data_dec(pd_educational)\n",
    "    \n",
    "    # Normalize the data before we send it to linear regression model to learn this data:\n",
    "    ## Note: we want to normalize test data using same mean and std as train!\n",
    "    train_mean = pd_train.mean()\n",
    "    train_std = pd_train.std()\n",
    "    \n",
    "    pd_train = (pd_train - train_mean) / train_std\n",
    "    pd_test = (pd_test- train_mean) / train_std\n",
    "    \n",
    "    train_features = pd_train.copy()\n",
    "    test_features = pd_test.copy()\n",
    "    \n",
    "    train_labels = train_features.pop('meter_reading')\n",
    "    test_labels = test_features.pop('meter_reading')\n",
    "    \n",
    "    return (train_features,train_labels), (test_features,test_labels), timestamp_train, timestamp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_s, test_data_s, timestamp_train_s, timestamp_test_s = prepare_data_simple_encoding_dec(pd_educational)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression using simple encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression_model_s, history_s = learn_parameters(train_data_s, test_data_s, 0.00003, 256 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_history(history_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_test_and_prediction(test_data_s, timestamp_test_s, linear_regression_model_s, 'simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_linear_regression_weights(train_data_s,linear_regression_model_s, 'simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse_metric(y_pred,y_test):\n",
    "  return np.sqrt(np.mean((y_pred - y_test)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below shows the mean squared error metric for linear regression with simple encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_s = test_data_s[0]\n",
    "test_labels_s = test_data_s[1]\n",
    "test_features_new = test_features_s.copy()\n",
    "y_pred_s = linear_regression_model_s.predict(test_features_s)\n",
    "y_norm_s= pd.DataFrame(y_pred_s, columns = ['prediction'])\n",
    "y_norm_s['timestamp'] = np.array(timestamp_test_s)\n",
    "test_features_new['meter_reading']  = test_labels_s\n",
    "test_features_new['timestamp']  = np.array(timestamp_test_s) \n",
    "\n",
    "y_test_all = test_features_new.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"meter_reading\"]).meter_reading.values\n",
    "y_hat_all = y_norm_s.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"prediction\"]).prediction.values\n",
    "calculate_rmse_metric(y_test_all,y_hat_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below does polynomial encoding to the input data. Specifically, I do polynomial encoding on timestamp and wind features. I also conver the year built feature to a categorical feature using 40 year periods as bins.\n",
    "For timestamp feature: Given that energy consumption has clear daily variations, if we encode day as a numeric feature, then even though 0000hrs follows right after 2359hrs, they will numerically look like they are far apart. This encoding solves this problem by substituting day feature with day_sin and day_cos feature, with frequency that corresponds to a 24h.\n",
    "For wind feature: Wind_direction feature in units of degrees has similar issue as described above, where 0 and 359 degrees are numerically far away but in reality they are close. Thus I substituted wind_speed and wind_direction features by combining them together into wind_x and wind_y features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_polynomial_encoding_dec(pd_dataframe):\n",
    "    # Wind feature encoding:\n",
    "    pd_educational = pd_dataframe.copy()\n",
    "    wind_speed = pd_educational.pop('wind_speed') \n",
    "    wind_direction = pd_educational.pop('wind_direction')*np.pi/180 # wind direction in radians \n",
    "    \n",
    "    pd_educational['wind_x'] = wind_speed * np.cos(wind_direction) \n",
    "    pd_educational['wind_y'] = wind_speed * np.sin(wind_direction) \n",
    "    \n",
    "    # Timestamp feature encoding:\n",
    "    timestamp = pd.to_datetime(pd_educational[\"timestamp\"]).map(datetime.datetime.timestamp) \n",
    "    day = 24*60*60 \n",
    "    week = 7*day \n",
    "    month = 30*day \n",
    "    year = (365.2425)*day \n",
    "    pd_educational['day_sin'] = np.sin(timestamp * (2 * np.pi / day)) \n",
    "    pd_educational['day_cos'] = np.cos(timestamp * (2 * np.pi / day)) \n",
    "    \n",
    "    pd_educational['week_sin'] = np.sin(timestamp * (2 * np.pi / week)) \n",
    "    pd_educational['week_cos'] = np.cos(timestamp * (2 * np.pi / week)) \n",
    "    \n",
    "    pd_educational['year_sin'] = np.sin(timestamp * (2 * np.pi / year)) \n",
    "    pd_educational['year_cos'] = np.cos(timestamp * (2 * np.pi / year)) \n",
    "    \n",
    "    pd_educational['is_weekday'] = (pd.to_datetime(pd_educational[\"timestamp\"]).dt.weekday.values < 5).astype(int) \n",
    "    \n",
    "    # Year_built feature encoding:\n",
    "    ## Looking at the year_built histogram, there seems to be 3 waves of building \n",
    "    ## '1900-1940', '1940-1980', '1980-today'. I will split this column in those  \n",
    "    ## 3 features and I will assign them values 0, 1 and 2:  \n",
    "    year_built = pd_educational.pop('year_built') \n",
    "    pd_educational['year_built_range'] = ((year_built.values-1900)/40).astype(int) \n",
    "    \n",
    "    pd_train, pd_test, timestamp_train, timestamp_test = split_data_dec(pd_educational) \n",
    "    \n",
    "    # Normalize the data before we send it to linear regression model to learn this data: \n",
    "    ## Note: we want to normalize test data using same mean and std as train! \n",
    "    train_mean = pd_train.mean() \n",
    "    train_std = pd_train.std() \n",
    "    \n",
    "    pd_train = (pd_train - train_mean) / train_std \n",
    "    pd_test = (pd_test- train_mean) / train_std \n",
    "    \n",
    "    train_features = pd_train.copy() \n",
    "    test_features = pd_test.copy() \n",
    "    \n",
    "    train_labels = train_features.pop('meter_reading') \n",
    "    test_labels = test_features.pop('meter_reading') \n",
    "    \n",
    "    return (train_features,train_labels), (test_features,test_labels), timestamp_train, timestamp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_p, test_data_p, timestamp_train_p, timestamp_test_p = prepare_data_polynomial_encoding_dec(pd_educational) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression_model_p, history_p = learn_parameters(train_data_p, test_data_p, 0.00003, 256 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_history(history_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_test_and_prediction(test_data_p, timestamp_test_p, linear_regression_model_p, 'polynomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_linear_regression_weights(train_data_p,linear_regression_model_p, 'polynomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_p = test_data_p[0]\n",
    "test_labels_p = test_data_p[1]\n",
    "test_features_new = test_features_p.copy()\n",
    "y_pred_p = linear_regression_model_p.predict(test_features_p)\n",
    "y_norm_p= pd.DataFrame(y_pred_p, columns = ['prediction'])\n",
    "y_norm_p['timestamp'] = np.array(timestamp_test_p)\n",
    "test_features_new['meter_reading']  = test_labels_p\n",
    "test_features_new['timestamp']  = np.array(timestamp_test_p) \n",
    "\n",
    "y_test_all = test_features_new.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"meter_reading\"]).meter_reading.values\n",
    "y_hat_all = y_norm_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"prediction\"]).prediction.values\n",
    "calculate_rmse_metric(y_test_all,y_hat_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Regression with Simple Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, timestamp_train, timestamp_test = prepare_data_simple_encoding_dec(pd_educational)\n",
    "(X_train,y_train) = train_data\n",
    "(X_test,y_test) = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeRegressor()#max_depth=400)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_hat = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = {'prediction': y_hat, 'timestamp': timestamp_test}\n",
    "y_norm_p = pd.DataFrame(data=pred)\n",
    "test_val = {'meter_reading':y_test, 'timestamp': timestamp_test}\n",
    "test_features_new_p= pd.DataFrame(data=test_val)\n",
    "\n",
    "figure(figsize =(15,7))\n",
    "plt.plot(test_features_new_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"meter_reading\"]), color = 'C1', label = 'data')\n",
    "plt.plot(y_norm_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"prediction\"]), color = 'gray', label = 'prediction')\n",
    "plt.xlabel('timestamp', fontsize = 12)\n",
    "plt.ylabel('Normalized electricity consumption', fontsize = 12)\n",
    "plt.title('Prediction of electricity consumption using decision tree regressor', fontsize = 14)\n",
    "len_ts = len(timestamp_test.values)\n",
    "plt.xticks([timestamp_test.values[0],timestamp_test.values[int(len_ts/2)],timestamp_test.values[-1]], fontsize = '12')\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_all = test_features_new_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"meter_reading\"]).meter_reading.values\n",
    "y_hat_all = y_norm_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"prediction\"]).prediction.values\n",
    "\n",
    "calculate_rmse_metric(y_test_all,y_hat_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Regrssion with polynomial encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, timestamp_train, timestamp_test = prepare_data_polynomial_encoding_dec(pd_educational)\n",
    "(X_train,y_train) = train_data\n",
    "(X_test,y_test) = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeRegressor()#max_depth=400)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_hat = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = {'prediction': y_hat, 'timestamp': timestamp_test}\n",
    "y_norm_p = pd.DataFrame(data=pred)\n",
    "test_val = {'meter_reading':y_test, 'timestamp': timestamp_test}\n",
    "test_features_new_p= pd.DataFrame(data=test_val)\n",
    "\n",
    "figure(figsize =(15,7))\n",
    "plt.plot(test_features_new_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"meter_reading\"]), color = 'C1', label = 'data')\n",
    "plt.plot(y_norm_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"prediction\"]), color = 'gray', label = 'prediction')\n",
    "plt.xlabel('timestamp', fontsize = 12)\n",
    "plt.ylabel('Normalized electricity consumption', fontsize = 12)\n",
    "plt.title('Prediction of electricity consumption using decision tree regressor', fontsize = 14)\n",
    "len_ts = len(timestamp_test.values)\n",
    "plt.xticks([timestamp_test.values[0],timestamp_test.values[int(len_ts/2)],timestamp_test.values[-1]], fontsize = '12')\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_all = test_features_new_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"meter_reading\"]).meter_reading.values\n",
    "y_hat_all = y_norm_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"prediction\"]).prediction.values\n",
    "\n",
    "calculate_rmse_metric(y_test_all,y_hat_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree regression with no encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_train = pd_educational.loc[pd.to_datetime(pd_educational[\"timestamp\"]) < datetime.datetime(2016, 12, 1)] \n",
    "pd_test = pd_educational.loc[pd.to_datetime(pd_educational[\"timestamp\"]) > datetime.datetime(2016, 11, 30)]\n",
    "\n",
    "y_train = pd_train.pop('meter_reading')\n",
    "y_test = pd_test.pop('meter_reading')\n",
    "X_train = pd_train\n",
    "X_test = pd_test\n",
    "timestamp_train = X_train.pop('timestamp')\n",
    "timestamp_test = X_test.pop('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeRegressor()#max_depth=400)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_hat = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = {'prediction': y_hat, 'timestamp': timestamp_test}\n",
    "y_norm_p = pd.DataFrame(data=pred)\n",
    "test_val = {'meter_reading':y_test, 'timestamp': timestamp_test}\n",
    "test_features_new_p= pd.DataFrame(data=test_val)\n",
    "\n",
    "figure(figsize =(15,7))\n",
    "plt.plot(test_features_new_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"meter_reading\"]), color = 'C1', label = 'data')\n",
    "plt.plot(y_norm_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"prediction\"]), color = 'gray', label = 'prediction')\n",
    "plt.xlabel('timestamp', fontsize = 12)\n",
    "plt.ylabel('Electricity consumption (kWh)', fontsize = 12)\n",
    "plt.title('Prediction of electricity consumption using decision tree regressor (no encoding)', fontsize = 14)\n",
    "len_ts = len(timestamp_test.values)\n",
    "plt.xticks([timestamp_test.values[0],timestamp_test.values[int(len_ts/2)],timestamp_test.values[-1]], fontsize = '12')\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.std(y_test.values)\n",
    "y_test_all = test_features_new_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"meter_reading\"]).meter_reading.values\n",
    "y_hat_all = y_norm_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"prediction\"]).prediction.values\n",
    "calculate_rmse_metric(y_test_all,y_hat_all)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forst Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest regression with simple encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, timestamp_train, timestamp_test = prepare_data_simple_encoding_dec(pd_educational)\n",
    "(X_train,y_train) = train_data\n",
    "(X_test,y_test) = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestRegressor(n_estimators=30)#max_depth=400)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_hat = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = {'prediction': y_hat, 'timestamp': timestamp_test}\n",
    "y_norm_p = pd.DataFrame(data=pred)\n",
    "test_val = {'meter_reading':y_test, 'timestamp': timestamp_test}\n",
    "test_features_new_p= pd.DataFrame(data=test_val)\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']\n",
    "\n",
    "figure(figsize =(15,7))\n",
    "plt.plot(test_features_new_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"meter_reading\"]), color = 'C1', label = 'data')\n",
    "plt.plot(y_norm_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"prediction\"]), color = 'gray', label = 'prediction')\n",
    "plt.xlabel('December 2016', fontsize = 24)\n",
    "plt.ylabel('Electricity consumption (norm)', fontsize = 24)\n",
    "#plt.title('Prediction of electricity consumption using random forest regressor and simple encoding', fontsize = 14)\n",
    "len_ts = len(timestamp_test.values)\n",
    "plt.xticks([])\n",
    "#plt.xticks([timestamp_test.values[0],timestamp_test.values[int(len_ts/2)],timestamp_test.values[-1]], fontsize = 20)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.legend( fontsize = 20, loc = 'upper left')\n",
    "plt.savefig('RFR_simple_Dec.pdf', transparency = True,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_all = test_features_new_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"meter_reading\"]).meter_reading.values\n",
    "y_hat_all = y_norm_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"prediction\"]).prediction.values\n",
    "calculate_rmse_metric(y_test_all,y_hat_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest regression with polynomial encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, timestamp_train, timestamp_test = prepare_data_polynomial_encoding_dec(pd_educational)\n",
    "(X_train,y_train) = train_data\n",
    "(X_test,y_test) = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestRegressor(n_estimators=30)#max_depth=400)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_hat = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = {'prediction': y_hat, 'timestamp': timestamp_test}\n",
    "y_norm_p = pd.DataFrame(data=pred)\n",
    "test_val = {'meter_reading':y_test, 'timestamp': timestamp_test}\n",
    "test_features_new_p= pd.DataFrame(data=test_val)\n",
    "\n",
    "figure(figsize =(15,7))\n",
    "plt.plot(test_features_new_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"meter_reading\"]), color = 'C1', label = 'data')\n",
    "plt.plot(y_norm_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"prediction\"]), color = 'gray', label = 'prediction')\n",
    "plt.xlabel('timestamp', fontsize = 12)\n",
    "plt.ylabel('Normalized electricity consumption', fontsize = 12)\n",
    "plt.title('Prediction of electricity consumption using random forest regressor (polynomial encoding)', fontsize = 14)\n",
    "len_ts = len(timestamp_test.values)\n",
    "plt.xticks([timestamp_test.values[0],timestamp_test.values[int(len_ts/2)],timestamp_test.values[-1]], fontsize = '12')\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_all = test_features_new_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"meter_reading\"]).meter_reading.values\n",
    "y_hat_all = y_norm_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"prediction\"]).prediction.values\n",
    "calculate_rmse_metric(y_test_all,y_hat_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forst regression with no encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_train = pd_educational.loc[pd.to_datetime(pd_educational[\"timestamp\"]) < datetime.datetime(2016, 12, 1)] \n",
    "pd_test = pd_educational.loc[pd.to_datetime(pd_educational[\"timestamp\"]) > datetime.datetime(2016, 11, 30)]\n",
    "\n",
    "y_train = pd_train.pop('meter_reading')\n",
    "y_test = pd_test.pop('meter_reading')\n",
    "X_train = pd_train\n",
    "X_test = pd_test\n",
    "timestamp_train = X_train.pop('timestamp')\n",
    "timestamp_test = X_test.pop('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestRegressor(n_estimators=30)#max_depth=400)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_hat = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = {'prediction': y_hat, 'timestamp': timestamp_test}\n",
    "y_norm_p = pd.DataFrame(data=pred)\n",
    "test_val = {'meter_reading':y_test, 'timestamp': timestamp_test}\n",
    "test_features_new_p= pd.DataFrame(data=test_val)\n",
    "\n",
    "figure(figsize =(15,7))\n",
    "plt.plot(test_features_new_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"meter_reading\"]), color = 'C1', label = 'data')\n",
    "plt.plot(y_norm_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"prediction\"]), color = 'gray', label = 'prediction')\n",
    "plt.xlabel('timestamp', fontsize = 12)\n",
    "plt.ylabel('Electricity consumption (kWh)', fontsize = 12)\n",
    "plt.title('Prediction of electricity consumption using decision tree regressor (no encoding)', fontsize = 14)\n",
    "len_ts = len(timestamp_test.values)\n",
    "plt.xticks([timestamp_test.values[0],timestamp_test.values[int(len_ts/2)],timestamp_test.values[-1]], fontsize = '12')\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.std(y_test.values)\n",
    "y_test_all = test_features_new_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"meter_reading\"]).meter_reading.values\n",
    "y_hat_all = y_norm_p.groupby(by = \"timestamp\").mean().filter([\"timestamp\", \"prediction\"]).prediction.values\n",
    "calculate_rmse_metric(y_test_all,y_hat_all)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
